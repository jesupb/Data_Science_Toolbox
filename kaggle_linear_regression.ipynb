{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Linear regression example\n\nThis notebooks is based on the work by done by https://www.kaggle.com/code/sudhirnl7/linear-regression-tutorial.\n\n**Goales from this analysis:**\n\n- We will explore the data for data cleanup and some insights.\n- We will explore how to use any insights we get from the insights we get in our EDA phase (Data exploratory analysis) for feature engineering, including new categorical variables we might create from the raw data and interactions between features that will help increase model performance.","metadata":{}},{"cell_type":"markdown","source":"## Import Library and Dataset","metadata":{}},{"cell_type":"code","source":"# Import library\nimport pandas  as pd #Data manipulation\nimport numpy as np #Data manipulation\nimport matplotlib.pyplot as plt # Visualization\nimport seaborn as sns #Visualization\nplt.rcParams['figure.figsize'] = [8,5]\nplt.rcParams['font.size'] =14\nplt.rcParams['font.weight']= 'bold'\nplt.style.use('seaborn-whitegrid')","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:12.137442Z","iopub.execute_input":"2022-08-17T14:46:12.137967Z","iopub.status.idle":"2022-08-17T14:46:12.970422Z","shell.execute_reply.started":"2022-08-17T14:46:12.137901Z","shell.execute_reply":"2022-08-17T14:46:12.969346Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Import dataset\n#path ='dataset/'\npath = '../input/'\ndf_raw = pd.read_csv(path+'insurance.csv')\nprint('\\nNumber of rows and columns in the data set: ',df_raw.shape)\nprint('')","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:12.971727Z","iopub.execute_input":"2022-08-17T14:46:12.971984Z","iopub.status.idle":"2022-08-17T14:46:13.010547Z","shell.execute_reply.started":"2022-08-17T14:46:12.971938Z","shell.execute_reply":"2022-08-17T14:46:13.009603Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data exploration\n\nOur first step will be, as usual, taking a look at the raw data, so we can determine what kind of variables we are working with (categorical/quantitative), as well as check out general variable distribution and missing values. ","metadata":{}},{"cell_type":"code","source":"#Lets look into top few rows and columns in the dataset\ndf_raw.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:13.011915Z","iopub.execute_input":"2022-08-17T14:46:13.012174Z","iopub.status.idle":"2022-08-17T14:46:13.047295Z","shell.execute_reply.started":"2022-08-17T14:46:13.012126Z","shell.execute_reply":"2022-08-17T14:46:13.046330Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Data exploration\n#  Start by understanding the data (categorical vs. numeric, what's the range ie. min() and max())\ndf_raw.describe(include = \"all\")","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:13.048817Z","iopub.execute_input":"2022-08-17T14:46:13.049355Z","iopub.status.idle":"2022-08-17T14:46:13.101419Z","shell.execute_reply.started":"2022-08-17T14:46:13.049292Z","shell.execute_reply":"2022-08-17T14:46:13.100434Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"We have 4 quantitative variables (including the target variable [charges]) and 3 caegorical variables.","metadata":{}},{"cell_type":"code","source":"# check for missing values\nplt.figure(figsize=(12,4))\nsns.heatmap(df_raw.isnull(),cbar=False,cmap='viridis',yticklabels=False)\nplt.title('Missing value in the dataset');","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:13.102879Z","iopub.execute_input":"2022-08-17T14:46:13.103443Z","iopub.status.idle":"2022-08-17T14:46:13.406548Z","shell.execute_reply.started":"2022-08-17T14:46:13.103374Z","shell.execute_reply":"2022-08-17T14:46:13.405221Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"We can see there are no _null_ values in our dataset. In case there were, we'd have to think about how to impute the data.\nNext we check for correlated features.","metadata":{}},{"cell_type":"code","source":"# Check for correlated variables\ncorr = df_raw.corr()\nsns.heatmap(corr, cmap = 'Wistia', annot= True);\n\n# There doesn't seem to be any significant correlation between quantitative variables","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:13.408549Z","iopub.execute_input":"2022-08-17T14:46:13.409298Z","iopub.status.idle":"2022-08-17T14:46:13.749116Z","shell.execute_reply.started":"2022-08-17T14:46:13.409215Z","shell.execute_reply":"2022-08-17T14:46:13.747845Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Exploring relationships between the target variable and the independent variables visually\nFirst we'll take a look at how our target variable behaves when segmented by our categorical variables.","metadata":{}},{"cell_type":"code","source":"f = plt.figure(figsize=(14,6))\nax = f.add_subplot(121)\nsns.violinplot(x='sex', y='charges',data=df_raw,palette='Wistia',ax=ax)\nax.set_title('Violin plot of Charges vs sex')\n\nax = f.add_subplot(122)\nsns.violinplot(x='smoker', y='charges',data=df_raw,palette='magma',ax=ax)\nax.set_title('Violin plot of Charges vs smoker');","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:13.751406Z","iopub.execute_input":"2022-08-17T14:46:13.752328Z","iopub.status.idle":"2022-08-17T14:46:14.435011Z","shell.execute_reply.started":"2022-08-17T14:46:13.752225Z","shell.execute_reply":"2022-08-17T14:46:14.433738Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"- Left plot: [sex] doesn't seem to have any particular effect on the [changes] variable.\n- Right plot: There's definitely a difference between the charges for smokers vs non-smokers. Notice that the [charges] variable is bimodal when restricted to the [Smoker] = \"yes\" subsample, which indicates we might be able to further separate this population into two more groups (as we'll see shortly).\n\nNext let's see how # of children affects the target variable:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.boxplot(x='children', y='charges',hue='sex',data=df_raw,palette='rainbow')\nplt.title('Box plot of charges vs children');","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:14.436881Z","iopub.execute_input":"2022-08-17T14:46:14.437548Z","iopub.status.idle":"2022-08-17T14:46:14.993055Z","shell.execute_reply.started":"2022-08-17T14:46:14.437463Z","shell.execute_reply":"2022-08-17T14:46:14.992035Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"In general we don't identify visualy any hard evidence that might lead us to believe that the number of children could determine how much a person gets charged. There seems to be less variability for higher values (4 and more), which we can see happens because of there being less observations for these two groups:","metadata":{}},{"cell_type":"code","source":"print(df_raw['children'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:14.994589Z","iopub.execute_input":"2022-08-17T14:46:14.994925Z","iopub.status.idle":"2022-08-17T14:46:15.003544Z","shell.execute_reply.started":"2022-08-17T14:46:14.994864Z","shell.execute_reply":"2022-08-17T14:46:15.002586Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(14,6))\nax = f.add_subplot(121)\nsns.boxplot(x='region', y='charges',data=df_raw,palette='Wistia',ax=ax)\nax.set_title('Boxplot of Charges vs region')","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:15.004962Z","iopub.execute_input":"2022-08-17T14:46:15.005543Z","iopub.status.idle":"2022-08-17T14:46:15.366135Z","shell.execute_reply.started":"2022-08-17T14:46:15.005455Z","shell.execute_reply":"2022-08-17T14:46:15.364787Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"There doesn't seem to be a definite split between different regions, although we might want to keep an eye on the southeast, where we can see more spread among the data, indicating that there are higher charges here.","metadata":{}},{"cell_type":"markdown","source":"Next we explore how our target variable behaves when compared to our quantitative variables. We'll include a color dimension for the [smoker] variable since it is evident from our previous plots that it has visible effect on the [charges] variable:","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(df_raw, col=\"smoker\", hue=\"smoker\")\ng.map(sns.scatterplot, \"age\", \"charges\")\ng.add_legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:15.368333Z","iopub.execute_input":"2022-08-17T14:46:15.369203Z","iopub.status.idle":"2022-08-17T14:46:16.225136Z","shell.execute_reply.started":"2022-08-17T14:46:15.369112Z","shell.execute_reply":"2022-08-17T14:46:16.223793Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We can see there's a clear linear relationship between age and charges. Furthermore, the slope for the non-smoker population and the smoker population seems to be pretty much the same. We can see that each group (smokers and non smokers) can be clearly separated into two more groups.\n\nLet's see how our target variable behaves when compared to the [bmi] variable:","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(df_raw, col=\"smoker\", hue=\"smoker\")\ng.map(sns.scatterplot, \"bmi\", \"charges\")\ng.add_legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:16.227216Z","iopub.execute_input":"2022-08-17T14:46:16.227992Z","iopub.status.idle":"2022-08-17T14:46:17.062800Z","shell.execute_reply.started":"2022-08-17T14:46:16.227895Z","shell.execute_reply":"2022-08-17T14:46:17.061153Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**What could be causing this separation within the smokers group along the [charges] variable?** As can be seen from the plot on the left, it seems like there's a hard cut between bmi less than 30 and bmi more than 30, so it might be a good idea to include such a variable into our model upfront. For the plot on the right, we can't see this effect for the non-smoking population, and here again we can see (not as clearly as in the previous plot) that there's a subgroup within the non-smokers that's being charged more that the majority.","metadata":{}},{"cell_type":"code","source":"df_raw['bmi_more_than_30'] = np.where(df_raw['bmi'] < 30, 0, 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:17.065003Z","iopub.execute_input":"2022-08-17T14:46:17.065552Z","iopub.status.idle":"2022-08-17T14:46:17.078066Z","shell.execute_reply.started":"2022-08-17T14:46:17.065410Z","shell.execute_reply":"2022-08-17T14:46:17.073306Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Let's see how our new categorical variable splits the data:","metadata":{}},{"cell_type":"code","source":"f = plt.figure(figsize=(14,6))\nax = f.add_subplot(121)\nsns.scatterplot(x='age',y='charges',data=df_raw[df_raw.smoker == \"yes\"],palette='magma',hue='bmi_more_than_30',ax=ax)\nax.set_title('Scatter plot of Charges vs age (Smokers only)')\n\nax = f.add_subplot(122)\nsns.scatterplot(x='bmi',y='charges',data=df_raw[df_raw.smoker == \"yes\"],palette='viridis',hue='bmi_more_than_30')\nax.set_title('Scatter plot of Charges vs bmi (Smokers only)')\nplt.savefig('sc.png');","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:17.080482Z","iopub.execute_input":"2022-08-17T14:46:17.081521Z","iopub.status.idle":"2022-08-17T14:46:18.119760Z","shell.execute_reply.started":"2022-08-17T14:46:17.081440Z","shell.execute_reply":"2022-08-17T14:46:18.118830Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"As mentioned before, for the non-smoker population, there's a set of points that clearly deviates from the overall population. We'll definitely want to check out if we can identify any specific clusters when comparing all variables against each other, but when doing so we don't identify any variable that could lead to a conclusive split in this subset of the data -- in practice you might want to check in with the business to understand why these points differ from the others and this might reveal that we need some more features into our model. For the moment we'll define an ad-hoc hard-coded rule to separate them from the bulk and drop them.","metadata":{}},{"cell_type":"code","source":"# We'll revisit this problem in the outlier detection module. For the moment let's just apply a simple rule based on the observed values: \n\ndf_raw['outlier'] = (df_raw.charges > 5000 + 15000/70 * df_raw.age) * df_raw.smoker == \"no\"","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:18.121084Z","iopub.execute_input":"2022-08-17T14:46:18.121347Z","iopub.status.idle":"2022-08-17T14:46:18.127809Z","shell.execute_reply.started":"2022-08-17T14:46:18.121298Z","shell.execute_reply":"2022-08-17T14:46:18.127081Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(14,6))\nax = f.add_subplot(121)\nsns.scatterplot(x='age',y='charges',data=df_raw[df_raw.smoker == \"no\"],palette='magma',hue='outlier',ax=ax)\nax.set_title('Scatter plot of Charges vs age')","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:18.128795Z","iopub.execute_input":"2022-08-17T14:46:18.129196Z","iopub.status.idle":"2022-08-17T14:46:18.457441Z","shell.execute_reply.started":"2022-08-17T14:46:18.129155Z","shell.execute_reply":"2022-08-17T14:46:18.456203Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df = df_raw[df_raw.outlier == False]","metadata":{"execution":{"iopub.status.busy":"2022-08-17T14:46:18.459309Z","iopub.execute_input":"2022-08-17T14:46:18.460005Z","iopub.status.idle":"2022-08-17T14:46:18.468520Z","shell.execute_reply.started":"2022-08-17T14:46:18.459926Z","shell.execute_reply":"2022-08-17T14:46:18.467261Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing\nWe'll start by encoding categorical variables and splitting the data into a training set and a validation set:","metadata":{}},{"cell_type":"code","source":"# Dummy variable\ncategorical_columns = ['sex','smoker', 'region'] # we're not including the [bmi_more_than_30] variable since it's already encoded\ndf_encode = pd.get_dummies(data = df, prefix = 'cat', prefix_sep='_',\n               columns = categorical_columns,\n               drop_first =True,\n               dtype='int8')\n\n\ndf_encode.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:24.601130Z","iopub.execute_input":"2022-08-17T15:26:24.601415Z","iopub.status.idle":"2022-08-17T15:26:24.637386Z","shell.execute_reply.started":"2022-08-17T15:26:24.601377Z","shell.execute_reply":"2022-08-17T15:26:24.636527Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Let's include the smoker AND high bmi interaction term\ndf_encode['cat_smoker_and_bmi30'] = df_encode['cat_yes'] * df_encode['bmi_more_than_30']","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:30.867865Z","iopub.execute_input":"2022-08-17T15:26:30.868434Z","iopub.status.idle":"2022-08-17T15:26:30.872227Z","shell.execute_reply.started":"2022-08-17T15:26:30.868388Z","shell.execute_reply":"2022-08-17T15:26:30.871634Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Split data into training and test set\nfrom sklearn.model_selection import train_test_split\nX = df_encode.drop('charges',axis=1) # Independet variable\ny = df_encode['charges'] # dependent variable\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=23)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:32.612136Z","iopub.execute_input":"2022-08-17T15:26:32.612712Z","iopub.status.idle":"2022-08-17T15:26:32.910581Z","shell.execute_reply.started":"2022-08-17T15:26:32.612646Z","shell.execute_reply":"2022-08-17T15:26:32.909669Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Modeling\nWe'll try out first an OLS model with interaction between the [smoker] and [bmi_gt_30] variable, and [age].\n\nThen we'll try out a Lasso without any sort of feature selection in order to see if we get the same result or better than the first one.","metadata":{}},{"cell_type":"code","source":"# Model 1\nmod1_features = ['age','cat_yes', 'cat_smoker_and_bmi30']\nX_train_1 = X_train[mod1_features]\nX_test_1 = X_test[mod1_features]\n\n# Scikit Learn module\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_1,y_train) # Note: x_0 =1 is no need to add, sklearn will take care of it.\n\n#Parameter\n[lin_reg.intercept_]+list(lin_reg.coef_)\n#parameter_df = parameter_df.join(pd.Series(sk_theta, name='Sklearn_theta'))\n#parameter_df","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:34.891750Z","iopub.execute_input":"2022-08-17T15:26:34.892057Z","iopub.status.idle":"2022-08-17T15:26:35.046801Z","shell.execute_reply.started":"2022-08-17T15:26:34.892002Z","shell.execute_reply":"2022-08-17T15:26:35.046033Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Evaluate my model\ny_pred_1 = lin_reg.predict(X_test_1)\n\n#   Evaluvation: MSE\nfrom sklearn.metrics import mean_squared_error\nJ_mse_sk = mean_squared_error(y_pred_1, y_test)\nprint('SMSE on test set: ',  np.sqrt(J_mse_sk))\nprint('R2 on test set: ',  str(lin_reg.score(X_test_1, y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:37.260431Z","iopub.execute_input":"2022-08-17T15:26:37.260782Z","iopub.status.idle":"2022-08-17T15:26:37.268956Z","shell.execute_reply.started":"2022-08-17T15:26:37.260713Z","shell.execute_reply":"2022-08-17T15:26:37.268309Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"A 96% R2 is pretty good. We'll need to check if our assumptions hold, i.e. linearity, normality of the residuals and homoscedasticity.","metadata":{}},{"cell_type":"markdown","source":"## Assumption check\nWe'll verify that the model assumptions hold by residual analysis","metadata":{}},{"cell_type":"code","source":"# Let's check out if our assumptions hold via residual analysis\n# Check for Linearity\nf = plt.figure(figsize=(14,5))\nax = f.add_subplot(121)\nsns.scatterplot(y_test,y_pred_1,ax=ax,color='r')\nax.set_title('Check for Linearity:\\n Actual Vs Predicted value')\n\n# Check for Residual normality & mean\nax = f.add_subplot(122)\nsns.distplot((y_test - y_pred_1),ax=ax,color='b')\nax.axvline((y_test - y_pred_1).mean(),color='k',linestyle='--')\nax.set_title('Check for Residual normality & mean: \\n Residual eror');","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:41.235414Z","iopub.execute_input":"2022-08-17T15:26:41.236039Z","iopub.status.idle":"2022-08-17T15:26:41.642466Z","shell.execute_reply.started":"2022-08-17T15:26:41.235987Z","shell.execute_reply":"2022-08-17T15:26:41.641474Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Check for Multivariate Normality\n# Quantile-Quantile plot \nf,ax = plt.subplots(1,2,figsize=(14,6))\nimport scipy as sp\n_,(_,_,r)= sp.stats.probplot((y_test - y_pred_1),fit=True,plot=ax[0])\nax[0].set_title('Check for Multivariate Normality: \\nQ-Q Plot')\n\n#Check for Homoscedasticity\nsns.scatterplot(y = (y_test - y_pred_1), x= y_test, ax = ax[1],color='r')\nax[1].set_title('Check for Homoscedasticity: \\nResidual Vs Predicted');","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:44.803197Z","iopub.execute_input":"2022-08-17T15:26:44.803542Z","iopub.status.idle":"2022-08-17T15:26:45.409242Z","shell.execute_reply.started":"2022-08-17T15:26:44.803471Z","shell.execute_reply":"2022-08-17T15:26:45.408031Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Check for Multicollinearity\n#Variance Inflation Factor\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n  \n# VIF dataframe\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = X_train_1.columns\n  \n# calculating VIF for each feature\nvif_data[\"VIF\"] = [variance_inflation_factor(X_train_1.values, i)\n                          for i in range(len(X_train_1.columns))]\n  \nprint(vif_data)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T15:26:51.085397Z","iopub.execute_input":"2022-08-17T15:26:51.085730Z","iopub.status.idle":"2022-08-17T15:26:51.176379Z","shell.execute_reply.started":"2022-08-17T15:26:51.085648Z","shell.execute_reply":"2022-08-17T15:26:51.175562Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"1. Linearity seems to hold well enough.\n2. Our residuals are nicely centered around 0, although there seems to be some outliers, especially a couple of values our model is underestimating.\n3. Our residuals are fairly normal, as we can see from the qqplot, with the exception of the outliers we mentiones before. We might want to remove these outliers and fit our model again, then test for normality with a Shapiro Wilk test.\n4. Homoscedasticity kind of holds, but there's definitely more variance in both smoker samples (clusters 1 and 2), both with low as well as high bmi.\n5. There is no multicolinearity (VIF < 5)","metadata":{}}]}